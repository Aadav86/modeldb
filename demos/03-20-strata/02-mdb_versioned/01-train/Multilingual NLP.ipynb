{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP training example\n",
    "In this example, we'll train an NLP model for sentiment analysis of tweets using spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download spaCy language libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xx_ent_wiki_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-2.2.0/xx_ent_wiki_sm-2.2.0.tar.gz#egg=xx_ent_wiki_sm==2.2.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from xx_ent_wiki_sm==2.2.0) (2.2.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (4.43.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (41.2.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (7.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.18.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.5.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/miliu/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/venv/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('xx_ent_wiki_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download xx_ent_wiki_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And import the boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = \"verta-strata\"\n",
    "EN_S3_KEY = \"english-tweets.csv\"\n",
    "EN_FILENAME = EN_S3_KEY\n",
    "DE_S3_KEY = \"german-tweets.csv\"\n",
    "DE_FILENAME = DE_S3_KEY\n",
    "\n",
    "boto3.client('s3').download_file(S3_BUCKET, EN_S3_KEY, EN_FILENAME)\n",
    "boto3.client('s3').download_file(S3_BUCKET, DE_S3_KEY, DE_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and load data using our library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have coffee stomach... aaahhhh!  need food... ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOM DELONGE    &amp;lt;3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all is very far from being well in the life of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just created the account and logged in for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i could have been racking up on call of duty k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  have coffee stomach... aaahhhh!  need food... ...          0\n",
       "1                               TOM DELONGE    &lt;3          1\n",
       "2  all is very far from being well in the life of...          0\n",
       "3  Just created the account and logged in for the...          1\n",
       "4  i could have been racking up on call of duty k...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "en_data = pd.read_csv(EN_FILENAME)\n",
    "de_data = pd.read_csv(DE_FILENAME)\n",
    "\n",
    "data = pd.concat([en_data, de_data], axis=0)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "utils.clean_data(data)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ModelDB\n",
    "ModelDB organizes our work, and enables us to log and version metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set email from environment\n",
      "set developer key from environment\n",
      "connection successfully established\n",
      "set existing Project: Tweet Classification from personal workspace\n",
      "set existing Experiment: SpaCy\n",
      "created new ExperimentRun: Run 997181584405191309407\n"
     ]
    }
   ],
   "source": [
    "from verta import Client\n",
    "\n",
    "client = Client('https://dev.verta.ai')\n",
    "client.set_project('Tweet Classification')\n",
    "client.set_experiment('SpaCy')\n",
    "run = client.set_experiment_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first record our code, configuration, dataset, and environment versions to a ModelDB repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set existing Repository: Verta Strata from personal workspace\n"
     ]
    }
   ],
   "source": [
    "repo = client.set_repository('Verta Strata')\n",
    "commit = repo.get_commit(branch='master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    require([\"base/js/namespace\"],function(Jupyter) {\n",
       "        Jupyter.notebook.save_checkpoint();\n",
       "    });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Branch: master)\n",
       "Commit dca076b0f24e38821c17120005445a4c2cfc8a0e6b3d70a1036b96c933a71a7a containing:\n",
       "config/hyperparams (Blob)\n",
       "data/tweets (Blob)\n",
       "env/python (Blob)\n",
       "notebooks/tweet-analysis (Blob)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verta.code import Notebook\n",
    "from verta.configuration import Hyperparameters\n",
    "from verta.dataset import S3\n",
    "from verta.environment import Python\n",
    "\n",
    "code_ver = Notebook()\n",
    "config_ver = Hyperparameters({'n_iter': 20})\n",
    "dataset_ver = S3([\n",
    "    \"s3://{}/{}\".format(S3_BUCKET, EN_S3_KEY),\n",
    "    \"s3://{}/{}\".format(S3_BUCKET, DE_S3_KEY),\n",
    "])\n",
    "env_ver = Python()\n",
    "\n",
    "commit.update(\"notebooks/tweet-analysis\", code_ver)\n",
    "commit.update(\"config/hyperparams\", config_ver)\n",
    "commit.update(\"data/tweets\", dataset_ver)\n",
    "commit.update(\"env/python\", env_ver)\n",
    "commit.save(\"Deployment-ready sentiment analysis\")\n",
    "\n",
    "commit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use a pre-trained model from spaCy and fine tune it in our new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('xx_ent_wiki_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the model with the current data using our library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16000 examples (12800 training, 3200 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "16.020\t0.747\t0.700\t0.723\n",
      "0.363\t0.751\t0.723\t0.737\n",
      "0.106\t0.752\t0.727\t0.739\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0300a3f9c079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/modeldb/demos/03-20-strata/02-mdb_versioned/01-train/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nlp, df, n_iter, n_texts)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtextcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# evaluate on the dev data split off in load_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import training\n",
    "\n",
    "training.train(nlp, data, n_iter=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and version the model\n",
    "We log the model itself as an artifact to ModelDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_model(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, link the commit to our Experiment Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_commit(\n",
    "    commit,\n",
    "    {\n",
    "        'notebook': \"notebooks/tweet-analysis\",\n",
    "        'hyperparameters': \"config/hyperparams\",\n",
    "        'training_data': \"data/tweets\",\n",
    "        'python_env': \"env/python\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you have a model that you can use to run predictions against. Follow the next step of this tutorial to see how to do it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
